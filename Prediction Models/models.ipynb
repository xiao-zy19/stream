{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>observationoffset</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>paO2</th>\n",
       "      <th>FiO2_x</th>\n",
       "      <th>FiO2_y</th>\n",
       "      <th>Glasgow score</th>\n",
       "      <th>BP</th>\n",
       "      <th>BUN</th>\n",
       "      <th>WBC x 1000</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>sodium</th>\n",
       "      <th>potassium</th>\n",
       "      <th>total bilirubin</th>\n",
       "      <th>actualicumortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141515.0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.823529</td>\n",
       "      <td>36.900429</td>\n",
       "      <td>108.5</td>\n",
       "      <td>69.034181</td>\n",
       "      <td>69.034181</td>\n",
       "      <td>6.689885</td>\n",
       "      <td>87.272727</td>\n",
       "      <td>75.049159</td>\n",
       "      <td>11.7</td>\n",
       "      <td>20.589048</td>\n",
       "      <td>133.145147</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141515.0</td>\n",
       "      <td>1</td>\n",
       "      <td>90.222222</td>\n",
       "      <td>36.958959</td>\n",
       "      <td>283.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.578818</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>74.894458</td>\n",
       "      <td>11.7</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141515.0</td>\n",
       "      <td>2</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>36.584615</td>\n",
       "      <td>108.5</td>\n",
       "      <td>68.208171</td>\n",
       "      <td>68.208171</td>\n",
       "      <td>6.462798</td>\n",
       "      <td>120.800000</td>\n",
       "      <td>74.731208</td>\n",
       "      <td>11.7</td>\n",
       "      <td>20.553918</td>\n",
       "      <td>133.426232</td>\n",
       "      <td>3.704932</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141515.0</td>\n",
       "      <td>3</td>\n",
       "      <td>87.875000</td>\n",
       "      <td>38.775000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6.342544</td>\n",
       "      <td>111.062500</td>\n",
       "      <td>74.559406</td>\n",
       "      <td>11.7</td>\n",
       "      <td>20.540583</td>\n",
       "      <td>133.569442</td>\n",
       "      <td>3.876114</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141515.0</td>\n",
       "      <td>4</td>\n",
       "      <td>85.875000</td>\n",
       "      <td>38.362500</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>6.218848</td>\n",
       "      <td>115.333333</td>\n",
       "      <td>74.379056</td>\n",
       "      <td>11.7</td>\n",
       "      <td>20.530217</td>\n",
       "      <td>133.714358</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid  observationoffset  heartrate  temperature   paO2  \\\n",
       "0           141515.0                  0  86.823529    36.900429  108.5   \n",
       "1           141515.0                  1  90.222222    36.958959  283.0   \n",
       "2           141515.0                  2  91.600000    36.584615  108.5   \n",
       "3           141515.0                  3  87.875000    38.775000   55.0   \n",
       "4           141515.0                  4  85.875000    38.362500   71.0   \n",
       "\n",
       "       FiO2_x      FiO2_y  Glasgow score          BP        BUN  WBC x 1000  \\\n",
       "0   69.034181   69.034181       6.689885   87.272727  75.049159        11.7   \n",
       "1  100.000000  100.000000       6.578818  111.000000  74.894458        11.7   \n",
       "2   68.208171   68.208171       6.462798  120.800000  74.731208        11.7   \n",
       "3   50.000000   50.000000       6.342544  111.062500  74.559406        11.7   \n",
       "4   70.000000   70.000000       6.218848  115.333333  74.379056        11.7   \n",
       "\n",
       "   bicarbonate      sodium  potassium  total bilirubin  actualicumortality  \n",
       "0    20.589048  133.145147   3.600000              1.2                   1  \n",
       "1    21.000000  132.000000   3.600000              1.2                   1  \n",
       "2    20.553918  133.426232   3.704932              1.2                   1  \n",
       "3    20.540583  133.569442   3.876114              1.2                   1  \n",
       "4    20.530217  133.714358   4.000000              1.2                   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_test_data.csv')\n",
    "df = df.groupby('patientunitstayid').apply(lambda x: x[x['observationoffset'] <= 24]).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7526\n",
      "1414\n"
     ]
    }
   ],
   "source": [
    "# select patient with actualicumortality = 1\n",
    "patient_alive = df[df['actualicumortality'] == 1]\n",
    "alive_id = patient_alive['patientunitstayid'].unique()\n",
    "\n",
    "# select patient with actualicumortality = 0\n",
    "patient_dead = df[df['actualicumortality'] == 0]\n",
    "dead_id = patient_dead['patientunitstayid'].unique()\n",
    "print(len(alive_id))\n",
    "print(len(dead_id))\n",
    "\n",
    "# patient_alive_sample = patient_alive.sample(n=patient_dead.shape[0])\n",
    "# data_set = pd.concat([patient_alive_sample, patient_dead])\n",
    "# print(data_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 55064\n",
      "Testing data size: 13860\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 确保随机性\n",
    "np.random.shuffle(dead_id)\n",
    "np.random.shuffle(alive_id)\n",
    "\n",
    "# 从alive_id中随机抽取与dead_id相同数量的ID\n",
    "alive_id = alive_id[:len(dead_id)]\n",
    "\n",
    "# 确定训练集和测试集的大小\n",
    "train_size = 0.8  # 训练集占 80%\n",
    "test_size = 0.2   # 测试集占 20%\n",
    "\n",
    "# 分别对死亡和生存的ID进行分割，确保训练集和测试集的平衡\n",
    "dead_train, dead_test = train_test_split(dead_id, test_size=test_size)\n",
    "alive_train, alive_test = train_test_split(alive_id, test_size=test_size)\n",
    "\n",
    "# 将训练集的死亡和生存ID合并，并从原始数据集中提取对应记录\n",
    "train_ids = np.concatenate((dead_train, alive_train))\n",
    "train_data = df[df['patientunitstayid'].isin(train_ids)]\n",
    "\n",
    "# 将测试集的死亡和生存ID合并，并从原始数据集中提取对应记录\n",
    "test_ids = np.concatenate((dead_test, alive_test))\n",
    "test_data = df[df['patientunitstayid'].isin(test_ids)]\n",
    "\n",
    "# 打印训练集和测试集的大小\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Testing data size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['actualicumortality', 'patientunitstayid'], axis=1)\n",
    "y_train = train_data['actualicumortality']\n",
    "X_test = test_data.drop(['actualicumortality', 'patientunitstayid'], axis=1)\n",
    "y_test = test_data['actualicumortality']\n",
    "\n",
    "# normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split data into train and test\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # X = data_set.drop(['actualicumortality', 'patientunitstayid', 'observationoffset'], axis=1)\n",
    "# X = data_set.drop(['actualicumortality', 'patientunitstayid'], axis=1)\n",
    "# y = data_set['actualicumortality']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, classification_report\n\u001b[0;32m      5\u001b[0m logistic_model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m logistic_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=10000, n_jobs=-1)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'confusion_matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print(f'classification_report: \\n{classification_report(y_test, y_pred)}')\n",
    "\n",
    "# show the coefficients\n",
    "print(logistic_model.coef_)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 71.21%\n",
      "confusion_matrix: \n",
      "[[4873 1954]\n",
      " [2036 4997]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      6827\n",
      "           1       0.72      0.71      0.71      7033\n",
      "\n",
      "    accuracy                           0.71     13860\n",
      "   macro avg       0.71      0.71      0.71     13860\n",
      "weighted avg       0.71      0.71      0.71     13860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_jobs=-1, n_estimators=200, max_depth=10)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'confusion_matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print(f'classification_report: \\n{classification_report(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 69.52%\n",
      "confusion_matrix: \n",
      "[[4660 2167]\n",
      " [2057 4976]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.69      6827\n",
      "           1       0.70      0.71      0.70      7033\n",
      "\n",
      "    accuracy                           0.70     13860\n",
      "   macro avg       0.70      0.70      0.70     13860\n",
      "weighted avg       0.70      0.70      0.70     13860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train xgboost model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_model = XGBClassifier(n_jobs=-1)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "y_pred = xgboost_model.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
    "print(f'confusion_matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "print(f'classification_report: \\n{classification_report(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
